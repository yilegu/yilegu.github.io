<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Yile (Yi) Gu - Principal Applied Scientist</title>
<style>
body { font-family: Arial, sans-serif; margin: 0; padding: 0; background-color: #f4f4f4; color: #333; }
header { background-color: #eae2f2; color: #333; padding: 40px 20px; text-align: center; }
header img { border-radius: 50%; width: 160px; height: 160px; object-fit: cover; margin-bottom: 15px; }
header h1 { margin: 10px 0 5px; font-size: 2.5em; }
header p { margin: 5px 0; font-size: 1.2em; color: #555; }
main { padding: 40px 20px; margin: 0 auto; max-width: 900px; }
section { margin-bottom: 40px; }
h2 { border-bottom: 2px solid #ddd; padding-bottom: 10px; margin-bottom: 20px; }
ul { list-style-type: disc; margin-left: 20px; }
li { margin-bottom: 10px; line-height: 1.6em; }
footer { background-color: #eae2f2; color: #333; text-align: center; padding: 20px; }
a { color: #0077aa; text-decoration: none; }
a:hover { text-decoration: underline; }
</style>
</head>
<body>
<header>
<img src="citations.jpeg" alt="Photo of Yile (Yi) Gu">
<h1>Yile (Yi) Gu</h1>
<p>Principal Applied Scientist, Amazon</p>
</header>
<main>
<section id="about">
<h2>About Me</h2>
<p>I am a principal applied scientist at Amazon focusing on cutting-edge methods for conversational AI, speech recognition and machine learning. According to my <a href="https://www.amazon.science/author/yi-gu">Amazon Science profile</a>, I have contributed to fifteen publications and two blog posts. My research spans Conversational AI, machine learning and security/privacy, with tags such as automatic speech recognition (ASR), speech, natural‑language processing (NLP), natural‑language understanding (NLU) and neural networks【668896757278115†L141-L166】. I work on scalable language models for speech recognition, leveraging multi‑modal data and advanced optimization techniques to improve both efficiency and accuracy.</p>
</section>
<section id="research-interests">
<h2>Research Interests</h2>
<ul>
<li>Conversational AI and dialogue systems</li>
<li>Machine learning and representation learning</li>
<li>Automatic speech recognition (ASR) and speech processing</li>
<li>Natural‑language processing (NLP) and natural‑language understanding (NLU)</li>
<li>Neural networks and large language models</li>
<li>Security, privacy and abuse prevention</li>
</ul>
</section>
<section id="selected-publications">
<h2>Selected Publications</h2>
<ol>
<li><strong>Speech recognition rescoring with large speech‑text foundation models (ICASSP 2025).</strong> Demonstrates how multi‑modal large language models combining speech and text can enhance automatic speech recognition by providing a second‑pass rescoring, leveraging large amounts of data for improved accuracy【668896757278115†L226-L229】.</li>
<li><strong>Towards ASR robust spoken language understanding through in‑context learning with word confusion networks (ICASSP 2024).</strong> Applies natural language understanding techniques to spoken language tasks by feeding transcribed speech into large language models and addressing challenges of noisy ASR output【668896757278115†L244-L247】.</li>
<li><strong>Paralinguistics‑enhanced large language modeling of spoken dialogue (ICASSP 2024).</strong> Investigates ways to incorporate paralinguistic cues such as sentiment, emotion and speaking style into large language models to achieve more human‑like spoken dialogue【668896757278115†L261-L264】.</li>
<li><strong>Align‑SLM: Textless spoken language models with reinforcement learning from AI feedback.</strong> A reinforcement learning framework that improves textless spoken language models by optimizing them with AI‑provided feedback, achieving state‑of‑the‑art performance on audio generation and non‑speech tasks【292725430128537†L37-L64】.</li>
<li><strong>Multi‑modal retrieval for large language model‑based speech recognition.</strong> Introduces multi‑modal retrieval combining k‑nearest‑neighbor language models and cross‑attention to dramatically improve automatic speech recognition and achieve state‑of‑the‑art performance【674814154262576†L50-L60】.</li>
<li><strong>Scaling laws for discriminative speech recognition rescoring models.</strong> Shows that the word error rate of speech recognition models follows a scaling law in relation to training data and model size, and demonstrates that pre‑trained models can achieve better performance with less training data【954391350198922†L49-L62】.</li>
<li><strong>Personalization for BERT‑based discriminative speech recognition rescoring.</strong> Explores personalization through gazetteers, prompting and cross‑attention, achieving over 10% improvement in word error rate, with prompts improving performance without additional training【209670084688595†L50-L61】.</li>
<li><strong>Mitigating closed‑model adversarial examples with Bayesian neural modeling for enhanced end‑to‑end speech recognition.</strong> Proposes a Bayesian neural network‑based detector to identify and mitigate adversarial examples, improving detection rates and reducing word error rate in speech recognition【660011539618013†L51-L64】.</li>
</ol>
</section>
</main>
<footer>
<p>&copy; 2025 Yile (Yi) Gu. All rights reserved.</p>
</footer>
</body>
</html>
